---
title: "Regression (IQ) mit KNN"
output: html_document
---

```{r echo = F, warning = F, message = F}
# Laden Sie benötigte Libraries...
```

# Vorhersage des IQ mit KNN-Regression

In dieser Aufgabe soll mittels KNN-Regression der Intelligenz-Quotient (IQ) von Kindern vorhergesagt werden (siehe auch andere Aufgabe).

## KNN-Regression erläutern

$k$-nearest-neighbors (KNN) ist ein sehr einfaches Verfahren, mit dem Daten klassifiziert oder eine Regression berechnet werden kann. Im Fall der Regression werden für einen Datensatz die nächsten $k \in \mathbb{N}$ Nachbarn ermittelt und der Mittelwert dieser $k$ Response-Variablen berechnet -- das ist der geschätzte Wert. Üblicherweise wird die euklidische Distanz zum Ermitteln der Nachbarn genutzt.

Ein Einführungsvideo finden Sie unter https://youtu.be/sTJApaBjong. Weitere Infos auch unter https://bookdown.org/tpinto_home/Regression-and-Classification/k-nearest-neighbours-regression.html

Beschreiben Sie mit eigenen Worten (180 bis 220 Wörter), wie dieses Verfahren für die Regression und Klassifikation angewandt werden kann. Was sind die Vor- und Nachteile? Was sind die Besonderheiten im Vergleich zu anderen Verfahren?

KNN kann für Regression verwendet werden, indem ein kontinuierlicher Zielwert vorhergesagt wird. Um eine Vorhersage für ein neues Objekt zu treffen, identifizieret der Algorithmus die k Objekte in den Trainingsdaten, die dem neuen Objekt im Merkmalsraum am ähnlichsten sind, und er würde den Mittelwert oder Median ihrer Zielwerte als Vorhersage für das neue Objekt verwenden.

KNN kann zur Klassifikation verwendet werden, indem ein diskreter Zielwert vorhergesagt wird. Zum Beispiel, um vorherzusagen, ob eine Person eine bestimmte Krankheit hat, basierend auf ihrer Krankengeschichte und ihren Testergebnissen. 

Vorteile des KNN Algorithmus sind, dass er flexibel einsetzbar ist, da er für Regression und Klassifikation verwendet werden kann. Außerdem erfordert er wenig Trainingsaufwand und ist robust gegenüber Ausreißern, da er auf den Werten der nächsten Nachbarn und nicht auf dem gesamten Datensatz basiert.

Nachteile des Algorithmus sind, dass er rechenintensiv ist, was zu Problemen bei großen Datensätzen führen kann. Außerdem ist das Ergebnis komplett von k abhängig, wurde ein falsches k gewählt, hat das Einfluss auf das Ergebnis.

Die Besonderheiten verglichen zu anderen Verfahren sind, dass KNN nicht-parametrisch ist, d.h. dass keine Annahmen über die funktionale Form der Beziehung zwischen den Merkmalen und dem Ziel gemacht werden, und es wird nicht vorausgesetzt, dass die Daten normalverteilt sind. Außerdem ist er instanzbasiert, d.h. es werden keine Modelle auf Grundlage der Trainingsdaten erstellt. 

## Daten importieren

Laden Sie abermals den Datensatz unter https://oc.informatik.hs-mannheim.de/s/K2nJQngd8N6o3M5/download in einen Data Frame.

```{r}
# Ihre Lösung:
#load data into data frame
url = 'https://oc.informatik.hs-mannheim.de/s/K2nJQngd8N6o3M5/download'
download.file(url,'download')
df = readRDS('download')
```

## KNN-Regression anwenden

### Anwendung

Wenden Sie für diesen Datensatz eine KNN-Regression an, um den IQ von Kindern in Abhängigkeit der Merkmale schätzen zu können. Im Package `caret` gibt es die Lernmethode `knn`, die dafür genutzt werden kann.

```{r}

# Ihre Lösung:
set.seed(42)
ctrl = trainControl(method = 'cv', number = 5)
knn.iq = train(IQ.child ~ IQ.mother + IQ.father + n.siblings, data = df, method = 'knn', trControl = ctrl, preProcess = c('center', 'scale'), tuneLength = 20)
knn.iq

```

### $k$?

Finden Sie heraus, welcher Wert für die Anzahl der nächsten Nachbarn am besten funktioniert. Beschreiben Sie, wie Sie das gemacht haben.

Der beste Wert für die Anzahl der nächsten Nachbarn ist k=9. Mit dem Parameter 'tuneLength = n' werden automatisch n aufeinander folgende k Werte ausprobiert und der mit dem niedrigsten RMSE (root mean squared error) genommen.

### $R^2$
Lassen Sie die $R^2$-Statistik berechnen. Wie sieht diese im Vergleich zur linearen Regression aus? Welches Verfahren ist besser?

R^2 für k=9 ist 54,7%. Damit ist der Wert höher als der der linearen Regression, wenn die Anzahl der Geschwister nicht als Faktor geführt wird. Unter diesen Umständen passt KNN also besser. Werden allerdings die Geschwister in Faktoren umgewandelt und dann die lineare Regression angewendet, ist diese mit 66% das besser beschreibende Modell. Wandelt man bei KNN die Geschwisteranzahl in Faktoren um, ist R^2 kleiner (47%) und k=11 wird ausgewählt.

```{r}
# Ihre Lösung:
```


